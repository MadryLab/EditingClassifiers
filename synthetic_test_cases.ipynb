{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, warnings, json\n",
    "from argparse import Namespace\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import torch as ch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import classifier_helpers\n",
    "import helpers.data_helpers as dh\n",
    "import helpers.context_helpers as coh\n",
    "import helpers.rewrite_helpers as rh\n",
    "import helpers.vis_helpers as vh\n",
    "import helpers.analysis_helpers as ah\n",
    "\n",
    "random_seed = np.random.randint(0, 1000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./helpers/config.json') as f:\n",
    "    args = Namespace(**json.load(f))\n",
    "    \n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = classifier_helpers.get_default_paths(args.dataset_name, arch=args.arch)\n",
    "DATASET_PATH, MODEL_PATH, MODEL_CLASS, ARCH, CD = ret\n",
    "CD = {k: v.split(',')[0] for k, v in CD.items()}\n",
    "\n",
    "ret = classifier_helpers.load_classifier(MODEL_PATH, MODEL_CLASS, ARCH,\n",
    "                            args.dataset_name, args.layernum) \n",
    "model, context_model, target_model = ret[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load base dataset and synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset, train_loader, val_loader = dh.get_dataset(args.dataset_name, DATASET_PATH,\n",
    "                                                        batch_size=32, workers=8)\n",
    "preprocessing_transform = None\n",
    "if args.arch.startswith('clip'):\n",
    "    base_dataset.transform_test = ret[-1]\n",
    "    preprocessing_transform = ret[-1]\n",
    "    _, val_loader = base_dataset.make_loaders(workers=args.num_workers, \n",
    "                                         batch_size=args.batch_size, \n",
    "                                         shuffle_val=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_file = f'data/synthetic/segmentations/{args.concepts}/concept_{args.dataset_name}_{args.concepts}_{args.concept_name}.pt'\n",
    "concept_info = ch.load(concept_file)\n",
    "concept_info['imgs'] = concept_info['imgs'].to(ch.float32) / 255.\n",
    "concept_info['masks'] = concept_info['masks'].to(ch.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict, data_info_dict = dh.obtain_train_test_splits(args, concept_info, \n",
    "                                                          CD, \n",
    "                                                          args.style, \n",
    "                                                          preprocess=preprocessing_transform,\n",
    "                                                          rng=np.random.RandomState(random_seed))\n",
    "data_info_dict.update({'style_name': args.style, 'concept_name': args.concept_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidx = np.random.choice(len(data_dict['test_data']['imgs']), 3, replace=False)\n",
    "vh.show_image_row([data_dict['train_data']['imgs']], title='Train (original)')\n",
    "vh.show_image_row([data_dict['train_data']['modified_imgs']], title='Train (modified)')\n",
    "vh.show_image_row([data_dict['test_data']['imgs'][sidx]], title='Test (original)')\n",
    "vh.show_image_row([data_dict['test_data']['modified_imgs_same'][sidx]], title='Test (modified w/ train style)')\n",
    "vh.show_image_row([data_dict['test_data']['modified_imgs_diff'][sidx]], title='Test (modified w/ other styles)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance on test set pre-rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-edit model accuracy\n",
    "cache_file = f'./cache/accuracy/{args.arch}_{args.dataset_name}.pt'\n",
    "Path(f'./cache/accuracy/').mkdir(parents=True)\n",
    "_, _, acc_pre = ah.eval_accuracy(model, val_loader, batch_size=args.batch_size, cache_file=cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Pre-rewrite eval on synthetic data\")\n",
    "\n",
    "log_keys = {'train': ['imgs', 'modified_imgs'],\n",
    "                'test': ['imgs', 'modified_imgs_same', 'modified_imgs_diff']}\n",
    "log_labels = {('train', 'imgs'): 'Original train images',\n",
    "              ('train', 'modified_imgs'): 'Modified train images',\n",
    "              ('test', 'imgs'): 'Original test images',\n",
    "              ('test', 'modified_imgs_same'): 'Modified test images w/ train style',\n",
    "              ('test', 'modified_imgs_diff'): 'Modified test images w/ other style',}\n",
    "\n",
    "RESULTS = {}\n",
    "for m in ['train', 'test']:\n",
    "    for k2 in log_keys[m]: \n",
    "        preds = ah.get_preds(context_model, data_dict[f'{m}_data'][k2],\n",
    "                                                   BS=args.batch_size).numpy()\n",
    "        acc = 100 * np.mean(preds == data_dict[f'{m}_data']['labels'].numpy())\n",
    "        print(f\"Subset: {log_labels[(m, k2)]} | Accuracy: {acc:.2f}\")\n",
    "        RESULTS[f'{m}_pre_{k2}'] = {'preds': preds, \n",
    "                                    'acc': acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform re-write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model = rh.edit_classifier(args, \n",
    "                                   data_dict['train_data'], \n",
    "                                   context_model, \n",
    "                                   target_model=target_model, \n",
    "                                   val_loader=val_loader,\n",
    "                                   caching_dir=f\"./cache/covariances/{args.dataset_name}_{ARCH}_layer{args.layernum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance on test set post-rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Post-rewrite eval on synthetic data\")\n",
    "\n",
    "for m in ['train', 'test']:\n",
    "    for k2 in log_keys[m]: \n",
    "        preds = ah.get_preds(context_model, data_dict[f'{m}_data'][k2],\n",
    "                                                   BS=args.batch_size).numpy()\n",
    "        acc = 100 * np.mean(preds == data_dict[f'{m}_data']['labels'].numpy())\n",
    "        RESULTS[f'{m}_post_{k2}'] = {'preds': preds, 'acc': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = ah.evaluate_rewrite_effect(data_dict, RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah.plot_improvement_bar(RESULTS, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, acc_post = ah.eval_accuracy(model, val_loader, batch_size=args.batch_size, cache_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
