{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, warnings\n",
    "from argparse import Namespace\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch as ch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import classifier_helpers\n",
    "import helpers.data_helpers as dh\n",
    "import helpers.context_helpers as coh\n",
    "import helpers.rewrite_helpers as rh\n",
    "import helpers.vis_helpers as vh\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'ImageNet' \n",
    "ARCH = 'clip_RN50'\n",
    "REWRITE_MODE = 'finetune_global'\n",
    "LAYERNUM = 24\n",
    "SYNTHETIC = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = classifier_helpers.get_default_paths(DATASET_NAME, arch=ARCH)\n",
    "DATASET_PATH, MODEL_PATH, MODEL_CLASS, ARCH, CD = ret\n",
    "ret = classifier_helpers.load_classifier(MODEL_PATH, MODEL_CLASS, ARCH,\n",
    "                            DATASET_NAME, LAYERNUM) \n",
    "model, context_model, target_model = ret[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load base dataset and typographic attack imagess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset imagenet..\n"
     ]
    }
   ],
   "source": [
    "preprocess = ret[-1]\n",
    "\n",
    "base_dataset, _, _ = dh.get_dataset(DATASET_NAME, DATASET_PATH,\n",
    "                                    batch_size=32, workers=8)\n",
    "base_dataset.transform_test = preprocess\n",
    "_, val_loader = base_dataset.make_loaders(workers=10, batch_size=50, shuffle_val=False)\n",
    "targets = ch.tensor(val_loader.dataset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load typographic attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = dh.get_typographic_attacks('./data/typographic', \n",
    "                                                   preprocess,\n",
    "                                                   synthetic=SYNTHETIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data\")\n",
    "vh.show_image_row([train_data['imgs'], train_data['masks'], train_data['modified_imgs']], \n",
    "                  ['Original', 'Mask', 'Modified'], fontsize=20,\n",
    "                  size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Typographic test set\")\n",
    "\n",
    "for filter, im in test_data.items():\n",
    "    with ch.no_grad():\n",
    "        preds = model(im.cuda()).cpu()\n",
    "        preds = ch.argmax(preds, dim=1)\n",
    "\n",
    "    vh.show_image_row([im],\n",
    "                      [filter],\n",
    "                      tlist=[[CD[p].split(',')[0] for p in preds.numpy()]],\n",
    "                   size=(5, 5),\n",
    "                   fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dict(model.visual.named_children()).keys())\n",
    "LAYERNUM_FT = int(keys[LAYERNUM].replace('layer', ''))\n",
    "\n",
    "\n",
    "train_args = {'ntrain': len(train_data['imgs']), # Number of exemplars\n",
    "            'arch': ARCH, # Network architecture\n",
    "            'mode_rewrite': REWRITE_MODE, # Rewriting method ['editing', 'finetune_local', 'finetune_global']\n",
    "            'layernum': LAYERNUM if REWRITE_MODE == 'editing' else LAYERNUM_FT, # Layer to modify\n",
    "            'nsteps': 20000 if REWRITE_MODE == 'editing' else 400, # Number of rewriting steps  \n",
    "            'lr': 1e-4, # Learning rate\n",
    "            'restrict_rank': True, # Whether or not to perform low-rank update\n",
    "            'nsteps_proj': 10, # Frequency of weight projection\n",
    "            'rank': 1, # Rank of subspace to project weights\n",
    "            'use_mask': True # Whether or not to use mask\n",
    "             }\n",
    "train_args = Namespace(**train_args)\n",
    "train_data['labels'] = ch.tensor([849]) # Label of first image\n",
    "\n",
    "context_model = rh.edit_classifier(train_args, \n",
    "                           train_data, \n",
    "                           context_model, \n",
    "                           target_model=target_model, \n",
    "                           val_loader=val_loader,\n",
    "                           caching_dir=f\"./covariances/{DATASET_NAME}_{ARCH}_layer{LAYERNUM}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filter in ['clean', 'ipod']:\n",
    "    im = test_data[filter]\n",
    "    with ch.no_grad():\n",
    "        preds = model(im.cuda()).cpu()\n",
    "        preds = ch.argmax(preds, dim=1)\n",
    "\n",
    "    vh.show_image_row([im],\n",
    "                      tlist=[[CD[p].split(',')[0] for p in preds.numpy()]],\n",
    "                   size=(5, 5),\n",
    "                   fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
